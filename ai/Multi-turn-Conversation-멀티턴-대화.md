# Multi-turn Conversation (ë©€í‹°í„´ ëŒ€í™”)

"ë‘˜ì˜ ì°¨ì´ê°€ ë­ì•¼?"ë¼ê³  ë¬¼ì—ˆì„ ë•Œ, AIê°€ "ë­ë‘ ë­ìš”?"ë¼ê³  ë˜ë¬»ëŠ”ë‹¤ë©´ ì–´ë–¨ê¹Œ?

## ê²°ë¡ ë¶€í„° ë§í•˜ë©´

**ë©€í‹°í„´(Multi-turn)** ì€ ì—¬ëŸ¬ ë²ˆì˜ ì™•ë³µ ëŒ€í™”ë¥¼ í†µí•´ **ë§¥ë½ì„ ìœ ì§€** í•˜ëŠ” ëŒ€í™” ë°©ì‹ì´ë‹¤. LLMì€ ê¸°ë³¸ì ìœ¼ë¡œ ê° ìš”ì²­ì„ ë…ë¦½ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ë¯€ë¡œ, ë©€í‹°í„´ì„ êµ¬í˜„í•˜ë ¤ë©´ **ì´ì „ ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì „ë‹¬** í•´ì•¼ í•œë‹¤.

```mermaid
sequenceDiagram
    participant U as User
    participant App as Application
    participant LLM as LLM

    Note over App: ëŒ€í™” íˆìŠ¤í† ë¦¬ ê´€ë¦¬

    U->>App: "Python ì •ë ¬ ë°©ë²•ì€?"
    App->>LLM: [User: Python ì •ë ¬ ë°©ë²•ì€?]
    LLM-->>App: "sort()ë‚˜ sorted()ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”"
    App->>U: "sort()ë‚˜ sorted()ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”"

    U->>App: "ë‘˜ì˜ ì°¨ì´ëŠ”?"
    App->>LLM: [User: Python ì •ë ¬ ë°©ë²•ì€?]<br/>[AI: sort()ë‚˜ sorted()...]<br/>[User: ë‘˜ì˜ ì°¨ì´ëŠ”?]
    LLM-->>App: "sort()ëŠ” ì›ë³¸ ë³€ê²½, sorted()ëŠ” ìƒˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜"
    App->>U: "sort()ëŠ” ì›ë³¸ ë³€ê²½, sorted()ëŠ” ìƒˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜"
```

| êµ¬ë¶„ | Single-turn | Multi-turn |
|------|-------------|------------|
| ëŒ€í™” íšŸìˆ˜ | 1íšŒ ì§ˆë¬¸-ë‹µë³€ | ì—¬ëŸ¬ ë²ˆ ì™•ë³µ |
| ë§¥ë½ ìœ ì§€ | âŒ ì—†ìŒ | âœ… ì´ì „ ëŒ€í™” ê¸°ì–µ |
| êµ¬í˜„ | ë‹¨ìˆœ | íˆìŠ¤í† ë¦¬ ê´€ë¦¬ í•„ìš” |
| ë¹„ìš© | ë‚®ìŒ | ë†’ìŒ (ì „ì²´ íˆìŠ¤í† ë¦¬ ì „ì†¡) |

---

## 1. ì™œ ë©€í‹°í„´ì´ í•„ìš”í•œê°€?

### 1.1 LLMì€ ê¸°ì–µë ¥ì´ ì—†ë‹¤

LLM APIë¥¼ ì§ì ‘ í˜¸ì¶œí•´ë³¸ ì ì´ ìˆë‹¤ë©´ ì´ìƒí•œ ì ì„ ë°œê²¬í–ˆì„ ê²ƒì´ë‹¤. ë¶„ëª… ë°©ê¸ˆ ëŒ€í™”í–ˆëŠ”ë°, ë‹¤ìŒ ì§ˆë¬¸ì—ì„œ ì´ì „ ë‚´ìš©ì„ ì „í˜€ ê¸°ì–µí•˜ì§€ ëª»í•œë‹¤.

```python
# Turn 1
response = llm.invoke("Pythonì—ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì •ë ¬í•˜ëŠ” ë°©ë²•ì€?")
# "list.sort() ë˜ëŠ” sorted(list)ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”."

# Turn 2
response = llm.invoke("ë‘˜ì˜ ì°¨ì´ëŠ” ë­ì•¼?")
# "ë­ë‘ ë­ì˜ ì°¨ì´ë¥¼ ë§ì”€í•˜ì‹œëŠ” ê±´ê°€ìš”?" ğŸ˜•
```

ì™œ ì´ëŸ° ì¼ì´ ë²Œì–´ì§ˆê¹Œ?

**LLM APIëŠ” Stateless(ë¬´ìƒíƒœ)ë‹¤.** ê° ìš”ì²­ì€ ì™„ì „íˆ ë…ë¦½ì ìœ¼ë¡œ ì²˜ë¦¬ëœë‹¤. ì„œë²„ ì¸¡ì—ì„œ ì´ì „ ëŒ€í™”ë¥¼ ì €ì¥í•˜ì§€ ì•ŠëŠ”ë‹¤. ë§ˆì¹˜ ë§¤ë²ˆ ìƒˆë¡œìš´ ì‚¬ëŒê³¼ ëŒ€í™”í•˜ëŠ” ê²ƒê³¼ ê°™ë‹¤.

### 1.2 ê·¸ë ‡ë‹¤ë©´ ChatGPTëŠ” ì–´ë–»ê²Œ?

"ì ê¹, ChatGPTëŠ” ì´ì „ ëŒ€í™”ë¥¼ ì˜ ê¸°ì–µí•˜ëŠ”ë°?"

ë§ë‹¤. í•˜ì§€ë§Œ ê·¸ê±´ **ChatGPT ì• í”Œë¦¬ì¼€ì´ì…˜** ì´ í•´ì£¼ëŠ” ê²ƒì´ì§€, LLM ìì²´ì˜ ê¸°ëŠ¥ì´ ì•„ë‹ˆë‹¤.

```mermaid
flowchart LR
    subgraph ChatGPT["ChatGPT Application"]
        direction TB
        UI[ì±„íŒ… UI]
        History[ëŒ€í™” íˆìŠ¤í† ë¦¬ ì €ì¥]
    end

    subgraph API["OpenAI API"]
        LLM[GPT-4 Model]
    end

    User((User)) --> UI
    UI --> History
    History -->|ì „ì²´ íˆìŠ¤í† ë¦¬ í¬í•¨| LLM
    LLM -->|ì‘ë‹µ| UI

    style History fill:#1565C0,color:#fff
    style LLM fill:#E3F2FD,color:#000
```

ChatGPT ì• í”Œë¦¬ì¼€ì´ì…˜ì´ í•˜ëŠ” ì¼:
1. ëª¨ë“  ëŒ€í™”ë¥¼ ì €ì¥
2. ìƒˆ ì§ˆë¬¸í•  ë•Œ **ì´ì „ ëŒ€í™” ì „ì²´ë¥¼ í•¨ê»˜ ì „ì†¡**
3. LLMì€ ê·¸ ì „ì²´ë¥¼ ë³´ê³  ë§¥ë½ì„ íŒŒì•…

**ì¦‰, ë©€í‹°í„´ì€ ì• í”Œë¦¬ì¼€ì´ì…˜ ë ˆë²¨ì—ì„œ êµ¬í˜„í•´ì•¼ í•˜ëŠ” ê¸°ëŠ¥ì´ë‹¤.**

### 1.3 ì§ì ‘ êµ¬í˜„í•œë‹¤ë©´?

ê°€ì¥ ë‹¨ìˆœí•œ ë©€í‹°í„´ êµ¬í˜„ì€ ì´ë ‡ë‹¤:

```python
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage

llm = ChatOpenAI(model="gpt-4")

# ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ì§ì ‘ ê´€ë¦¬
messages = []

# Turn 1
messages.append(HumanMessage(content="Pythonì—ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì •ë ¬í•˜ëŠ” ë°©ë²•ì€?"))
response = llm.invoke(messages)
messages.append(response)
print(response.content)
# "list.sort() ë˜ëŠ” sorted(list)ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”."

# Turn 2 - ì´ì „ ëŒ€í™”ê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ë§¥ë½ íŒŒì•… ê°€ëŠ¥!
messages.append(HumanMessage(content="ë‘˜ì˜ ì°¨ì´ëŠ” ë­ì•¼?"))
response = llm.invoke(messages)
messages.append(response)
print(response.content)
# "sort()ëŠ” ì›ë³¸ì„ ë³€ê²½í•˜ê³ , sorted()ëŠ” ìƒˆ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤." âœ…
```

ê°„ë‹¨í•´ ë³´ì¸ë‹¤. í•˜ì§€ë§Œ ì—¬ê¸°ì„œ ë¬¸ì œê°€ ì‹œì‘ëœë‹¤.

---

## 2. ë©€í‹°í„´ì˜ ë„ì „ ê³¼ì œ

### 2.1 ëŒ€í™”ê°€ ê¸¸ì–´ì§€ë©´?

ëŒ€í™”ê°€ 100í„´ì´ ë„˜ì–´ê°€ë©´ ì–´ë–»ê²Œ ë ê¹Œ?

```
Turn 1: 100 í† í°
Turn 2: 100 + 150 = 250 í† í°
Turn 3: 250 + 200 = 450 í† í°
...
Turn 50: ìˆ˜ë§Œ í† í° ğŸ’¥
```

**ë¬¸ì œ 1: í† í° ì œí•œ**

LLMì—ëŠ” ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° ì œí•œì´ ìˆë‹¤. GPT-4ëŠ” 8K~128K, ClaudeëŠ” 200Kê¹Œì§€. ì•„ë¬´ë¦¬ ì»¤ë„ ë¬´í•œí•˜ì§€ ì•Šë‹¤.

**ë¬¸ì œ 2: ë¹„ìš© í­ì¦**

ë§¤ ìš”ì²­ë§ˆë‹¤ ì „ì²´ íˆìŠ¤í† ë¦¬ë¥¼ ë³´ë‚´ë¯€ë¡œ, ëŒ€í™”ê°€ ê¸¸ì–´ì§ˆìˆ˜ë¡ ë¹„ìš©ì´ ëˆ„ì ë˜ì–´ ê¸‰ê²©í•˜ê²Œ ì¦ê°€í•œë‹¤. (í† í° ìˆ˜ê°€ ë“±ì°¨ìˆ˜ì—´ì˜ í•©ìœ¼ë¡œ ëŠ˜ì–´ë‚˜ $O(n^2)$ ì— ê°€ê¹Œì›Œì§„ë‹¤)

**ë¬¸ì œ 3: ì‘ë‹µ ì§€ì—°**

í† í°ì´ ë§ì•„ì§€ë©´ ì²˜ë¦¬ ì‹œê°„ë„ ëŠ˜ì–´ë‚œë‹¤.

### 2.2 í•´ê²°ì±…: ë©”ëª¨ë¦¬ ê´€ë¦¬ ì „ëµ

ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë‹¤ì–‘í•œ **ë©”ëª¨ë¦¬ ê´€ë¦¬ ì „ëµ** ì´ ë“±ì¥í–ˆë‹¤.

```mermaid
flowchart TB
    subgraph Strategies["ë©”ëª¨ë¦¬ ê´€ë¦¬ ì „ëµ"]
        direction LR
        Buffer["Buffer<br>ì „ì²´ ì €ì¥"]
        Window["Window<br>ìµœê·¼ Nê°œë§Œ"]
        Summary["Summary<br>ìš”ì•½ ì €ì¥"]
        Vector["Vector<br>ê²€ìƒ‰ ê¸°ë°˜"]
    end

    Buffer --> |"ì§§ì€ ëŒ€í™”"| OK1[âœ… ì í•©]
    Window --> |"ì¤‘ê°„ ëŒ€í™”"| OK2[âœ… ì í•©]
    Summary --> |"ê¸´ ëŒ€í™”"| OK3[âœ… ì í•©]
    Vector --> |"ë§¤ìš° ê¸´ ëŒ€í™”"| OK4[âœ… ì í•©]

    style Buffer fill:#E3F2FD,color:#000
    style Window fill:#E8F5E9,color:#000
    style Summary fill:#FFF3E0,color:#000
    style Vector fill:#FFEBEE,color:#000
```

---

## 3. LangChain ë©”ëª¨ë¦¬ êµ¬í˜„

LangChainì€ ë‹¤ì–‘í•œ ë©”ëª¨ë¦¬ ê´€ë¦¬ ì „ëµì„ ì œê³µí•œë‹¤.

> **ì°¸ê³ :** í˜„ì¬ LangChainì—ì„œëŠ” ìƒíƒœ ê´€ë¦¬ë¥¼ ìœ„í•´ `ConversationChain`ë³´ë‹¤ ë” ìœ ì—°í•˜ê³  ê°•ë ¥í•œ **LangGraph** ì‚¬ìš©ì„ ê¶Œì¥í•˜ëŠ” ì¶”ì„¸ë‹¤. ì´ ë¬¸ì„œì˜ ì˜ˆì œëŠ” ë©”ëª¨ë¦¬ì˜ ê¸°ë³¸ ê°œë…ì„ ì´í•´í•˜ê¸° ìœ„í•œ ê²ƒì´ë‹¤. ì‹¤ì œ í”„ë¡œë•ì…˜ì—ì„œëŠ” [LangGraph Persistence](https://langchain-ai.github.io/langgraph/how-tos/persistence/)ë¥¼ ì°¸ê³ í•˜ë¼.

### 3.1 ConversationBufferMemory (ì „ì²´ ì €ì¥)

ê°€ì¥ ë‹¨ìˆœí•œ ë°©ì‹. ëª¨ë“  ëŒ€í™”ë¥¼ ê·¸ëŒ€ë¡œ ì €ì¥í•œë‹¤.

```python
from langchain.chains import ConversationChain
from langchain_openai import ChatOpenAI
from langchain.memory import ConversationBufferMemory

memory = ConversationBufferMemory()

conversation = ConversationChain(
    llm=ChatOpenAI(model="gpt-4"),
    memory=memory,
    verbose=True
)

conversation.predict(input="Pythonì´ ë­ì•¼?")
conversation.predict(input="ì–´ë””ì— ì“°ì—¬?")  # Python ë§¥ë½ ìœ ì§€
conversation.predict(input="ë°°ìš°ê¸° ì–´ë ¤ì›Œ?")  # ì—¬ì „íˆ Python ì–˜ê¸°
```

| ì¥ì  | ë‹¨ì  |
|------|------|
| ëª¨ë“  ëŒ€í™” ë‚´ìš© ë³´ì¡´ | ë©”ëª¨ë¦¬ ë§ì´ ì‚¬ìš© |
| êµ¬í˜„ ë‹¨ìˆœ | ê¸´ ëŒ€í™”ì— ë¶€ì í•© |

**ì‚¬ìš© ì‹œê¸°:** ì§§ì€ ëŒ€í™”, ëª¨ë“  ë§¥ë½ì´ ì¤‘ìš”í•œ ê²½ìš°

### 3.2 ConversationBufferWindowMemory (ìµœê·¼ Nê°œ)

ìµœê·¼ Nê°œ í„´ë§Œ ìœ ì§€í•˜ê³  ë‚˜ë¨¸ì§€ëŠ” ë²„ë¦°ë‹¤.

```python
from langchain.memory import ConversationBufferWindowMemory

# ìµœê·¼ 5í„´ë§Œ ì €ì¥
memory = ConversationBufferWindowMemory(k=5)
```

| ì¥ì  | ë‹¨ì  |
|------|------|
| ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì œí•œ | ì˜¤ë˜ëœ ëŒ€í™” ì†ì‹¤ |
| ì˜ˆì¸¡ ê°€ëŠ¥í•œ ë¹„ìš© | ì´ˆë°˜ ë§¥ë½ ìŠìŒ |

**ì‚¬ìš© ì‹œê¸°:** ìµœê·¼ ë§¥ë½ë§Œ ì¤‘ìš”í•œ ê²½ìš° (ì˜ˆ: ì¼ë°˜ ìƒë‹´)

### 3.3 ConversationSummaryMemory (ìš”ì•½)

ëŒ€í™”ë¥¼ LLMìœ¼ë¡œ ìš”ì•½í•´ì„œ ì €ì¥í•œë‹¤.

```python
from langchain.memory import ConversationSummaryMemory
from langchain_openai import ChatOpenAI

memory = ConversationSummaryMemory(
    llm=ChatOpenAI(model="gpt-4")
)
```

| ì¥ì  | ë‹¨ì  |
|------|------|
| ê¸´ ëŒ€í™”ë„ ì••ì¶• ê°€ëŠ¥ | ìš”ì•½ ê³¼ì •ì—ì„œ ì •ë³´ ì†ì‹¤ |
| í•µì‹¬ë§Œ ìœ ì§€ | ìš”ì•½ì— ì¶”ê°€ ë¹„ìš© ë°œìƒ |

**ì‚¬ìš© ì‹œê¸°:** ë§¤ìš° ê¸´ ëŒ€í™”, í•µì‹¬ë§Œ í•„ìš”í•œ ê²½ìš°

### 3.4 ConversationSummaryBufferMemory (ìš”ì•½ + ìµœê·¼)

ê³¼ê±°ëŠ” ìš”ì•½í•˜ê³ , ìµœê·¼ ëŒ€í™”ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ëŠ” í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹.

```python
from langchain.memory import ConversationSummaryBufferMemory

memory = ConversationSummaryBufferMemory(
    llm=ChatOpenAI(model="gpt-4"),
    max_token_limit=2000  # ì´ ì´ìƒì´ë©´ ì˜¤ë˜ëœ ê²ƒ ìš”ì•½
)
```

| ì¥ì  | ë‹¨ì  |
|------|------|
| ìµœê·¼ ëŒ€í™”ëŠ” ìƒì„¸íˆ ìœ ì§€ | ì„¤ì •ì´ ë³µì¡í•¨ |
| ì˜¤ë˜ëœ ë§¥ë½ë„ ìš”ì•½ìœ¼ë¡œ ë³´ì¡´ | ìš”ì•½ ë¹„ìš© ë°œìƒ |

**ì‚¬ìš© ì‹œê¸°:** ê¸´ ëŒ€í™”ì—ì„œ ìµœê·¼ ë§¥ë½ì´ íŠ¹íˆ ì¤‘ìš”í•œ ê²½ìš°

### 3.5 ConversationTokenBufferMemory (í† í° ê¸°ë°˜)

í† í° ìˆ˜ë¡œ ë©”ëª¨ë¦¬ë¥¼ ê´€ë¦¬í•œë‹¤.

```python
from langchain.memory import ConversationTokenBufferMemory

memory = ConversationTokenBufferMemory(
    llm=ChatOpenAI(model="gpt-4"),
    max_token_limit=2000  # ìµœëŒ€ 2000 í† í°
)
```

**ì‚¬ìš© ì‹œê¸°:** í† í° ë¹„ìš© ì œì–´ê°€ ì¤‘ìš”í•œ ê²½ìš°

### 3.6 VectorStoreRetrieverMemory (ë²¡í„° ê²€ìƒ‰)

ëŒ€í™”ê°€ ë°œìƒí•  ë•Œë§ˆë‹¤ **ìë™ìœ¼ë¡œ ë²¡í„° DBì— ì €ì¥** í•˜ê³ , ìƒˆ ì§ˆë¬¸ì´ ë“¤ì–´ì˜¤ë©´ ì˜ë¯¸ì ìœ¼ë¡œ **ê´€ë ¨ëœ ê³¼ê±° ëŒ€í™”ë§Œ ê²€ìƒ‰** í•´ì„œ ì»¨í…ìŠ¤íŠ¸ì— í¬í•¨í•œë‹¤.

```python
from langchain.memory import VectorStoreRetrieverMemory
from langchain.chains import ConversationChain
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import Chroma

vectorstore = Chroma(embedding_function=OpenAIEmbeddings())
retriever = vectorstore.as_retriever(search_kwargs={"k": 5})

memory = VectorStoreRetrieverMemory(retriever=retriever)

conversation = ConversationChain(
    llm=ChatOpenAI(model="gpt-4"),
    memory=memory,
    verbose=True
)

# predict í˜¸ì¶œ ì‹œ, ëŒ€í™”ê°€ ë²¡í„° DBì— ì €ì¥ë˜ê³  ê´€ë ¨ ë‚´ìš©ì´ ê²€ìƒ‰ë¨
conversation.predict(input="ë‚´ ì´ë¦„ì€ í™ê¸¸ë™ì´ê³ , íŒŒì´ì¬ì„ ë°°ìš°ê³  ì‹¶ì–´.")
# ... 100í„´ í›„ ...
conversation.predict(input="ë‚´ ì´ë¦„ì´ ë­ë¼ê³  í–ˆì§€?")  # ê´€ë ¨ ëŒ€í™”ë¥¼ ê²€ìƒ‰í•´ì„œ ë‹µë³€
```

| ì¥ì  | ë‹¨ì  |
|------|------|
| ì˜ë¯¸ì ìœ¼ë¡œ ê´€ë ¨ëœ ê³¼ê±° ëŒ€í™” ê²€ìƒ‰ | ì„¤ì • ë³µì¡ |
| ë§¤ìš° ê¸´ ëŒ€í™” íˆìŠ¤í† ë¦¬ ê°€ëŠ¥ | ì¸í”„ë¼ í•„ìš” (ë²¡í„° DB) |

**ì‚¬ìš© ì‹œê¸°:** íŠ¹ì • ì£¼ì œ ê´€ë ¨ ê³¼ê±° ëŒ€í™” ì°¸ì¡°ê°€ í•„ìš”í•œ ê²½ìš°

### 3.7 ë©”ëª¨ë¦¬ ì„ íƒ ê°€ì´ë“œ

| Memory íƒ€ì… | ëŒ€í™” ê¸¸ì´ | ë¹„ìš© | ë³µì¡ë„ | ì¶”ì²œ ìƒí™© |
|------------|----------|------|--------|---------|
| BufferMemory | ì§§ìŒ | ë‚®ìŒ | ë‚®ìŒ | ë‹¨ìˆœ ì±—ë´‡ |
| BufferWindowMemory | ì¤‘ê°„ | ë‚®ìŒ | ë‚®ìŒ | ì¼ë°˜ ìƒë‹´ |
| SummaryMemory | ê¸º | ë†’ìŒ | ì¤‘ê°„ | ê¸´ ìƒë‹´ ì„¸ì…˜ |
| SummaryBufferMemory | ê¸º | ì¤‘ê°„ | ì¤‘ê°„ | ê· í˜•ì¡íŒ ì ‘ê·¼ |
| TokenBufferMemory | ì¤‘ê°„ | ì¤‘ê°„ | ì¤‘ê°„ | ë¹„ìš© ì œì–´ |
| VectorStoreMemory | ë§¤ìš° ê¸º | ë†’ìŒ | ë†’ìŒ | ì˜ë¯¸ ê²€ìƒ‰ í•„ìš” |

---

## 4. ì‹¤ì œ í™œìš© ì‚¬ë¡€

### 4.1 Multi-turnì´ í•„ìˆ˜ì¸ ê²½ìš°

**ê³ ê° ìƒë‹´ ì±—ë´‡**

```
User: "í™˜ë¶ˆí•˜ê³  ì‹¶ì–´ìš”"
Bot: "ë„¤, ì£¼ë¬¸ë²ˆí˜¸ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”"
User: "1234ì…ë‹ˆë‹¤"  â† "í™˜ë¶ˆ" ë§¥ë½ ìœ ì§€
Bot: "1234 ì£¼ë¬¸ í™•ì¸í–ˆìŠµë‹ˆë‹¤. í™˜ë¶ˆ ì‚¬ìœ ëŠ”?"
User: "ì‚¬ì´ì¦ˆê°€ ì•ˆ ë§ì•„ìš”"
Bot: "ì•Œê² ìŠµë‹ˆë‹¤. í™˜ë¶ˆ ì²˜ë¦¬í•˜ê² ìŠµë‹ˆë‹¤"
```

**ì½”ë”© íŠœí„°**

```
User: "for ë¬¸ ì‚¬ìš©ë²• ì•Œë ¤ì¤˜"
AI: [for ë¬¸ ì„¤ëª…]
User: "ì˜ˆì œ ë³´ì—¬ì¤˜"  â† for ë¬¸ ë§¥ë½ ìœ ì§€
AI: [for ë¬¸ ì˜ˆì œ]
User: "rangeëŠ” ë­ì•¼?"  â† ì—¬ì „íˆ for ë¬¸ ë§¥ë½
AI: [range ì„¤ëª…]
```

### 4.2 Single-turnìœ¼ë¡œ ì¶©ë¶„í•œ ê²½ìš°

- ê²€ìƒ‰ ì—”ì§„ (ë…ë¦½ì ì¸ ê²€ìƒ‰)
- ë²ˆì—­ ì„œë¹„ìŠ¤ (ë¬¸ì¥ë³„ ë²ˆì—­)
- í…ìŠ¤íŠ¸ ë¶„ë¥˜ (ê°ì„± ë¶„ì„ ë“±)
- ë¬¸ì„œ ìš”ì•½ (í•œ ë²ˆì— ìš”ì•½)

---

## 5. êµ¬í˜„ íŒ

### 5.1 ì„¸ì…˜ ê´€ë¦¬

ì‚¬ìš©ìë³„ë¡œ ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ë¶„ë¦¬í•´ì•¼ í•œë‹¤.

```python
from datetime import datetime

user_sessions = {}

def get_or_create_session(user_id):
    if user_id not in user_sessions:
        user_sessions[user_id] = {
            "messages": [],
            "created_at": datetime.now()
        }
    return user_sessions[user_id]
```

### 5.2 íƒ€ì„ì•„ì›ƒ ì„¤ì •

ì˜¤ë˜ëœ ì„¸ì…˜ì€ ì •ë¦¬í•´ì•¼ í•œë‹¤.

```python
SESSION_TIMEOUT = 1800  # 30ë¶„

def is_session_expired(session):
    elapsed = (datetime.now() - session["last_activity"]).seconds
    return elapsed > SESSION_TIMEOUT
```

### 5.3 ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° ê´€ë¦¬

```python
MAX_MESSAGES = 20

def add_message(session, message):
    session["messages"].append(message)

    if len(session["messages"]) > MAX_MESSAGES:
        session["messages"] = session["messages"][-MAX_MESSAGES:]
```

### 5.4 ì¤‘ìš” ì •ë³´ëŠ” ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì—

ë¨¼ ê³¼ê±°ì˜ ëŒ€í™”ëŠ” ìŠí˜€ì§ˆ ìˆ˜ ìˆë‹¤. ì¤‘ìš”í•œ ì •ë³´ëŠ” ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— ì €ì¥í•˜ë¼.

```python
system_prompt = """
ì‚¬ìš©ì ì •ë³´:
- ì´ë¦„: í™ê¸¸ë™
- ì„ í˜¸ ì–¸ì–´: Python
- ì´ì „ ì§ˆë¬¸ ì£¼ì œ: ì •ë ¬ ì•Œê³ ë¦¬ì¦˜
"""
```

---

## 6. ì •ë¦¬

### ì™œ ë©€í‹°í„´ì´ í•„ìš”í•œê°€?

LLM APIëŠ” **Stateless** ë‹¤. ì´ì „ ëŒ€í™”ë¥¼ ê¸°ì–µí•˜ì§€ ì•ŠëŠ”ë‹¤. ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¥¼ ìœ„í•´ì„œëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ **ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ê´€ë¦¬** í•´ì•¼ í•œë‹¤.

### í•µì‹¬ ê°œë…

| ê°œë… | ì„¤ëª… |
|------|------|
| Single-turn | ë…ë¦½ì ì¸ 1íšŒ ì§ˆë¬¸-ë‹µë³€ |
| Multi-turn | ë§¥ë½ì„ ìœ ì§€í•˜ë©° ì—°ì† ëŒ€í™” |
| ë©”ëª¨ë¦¬ ê´€ë¦¬ | í† í° ì œí•œê³¼ ë¹„ìš© ë•Œë¬¸ì— í•„ìš” |

### êµ¬í˜„ í•µì‹¬

```python
# 1. íˆìŠ¤í† ë¦¬ ì €ì¥
messages = []

# 2. ìƒˆ ë©”ì‹œì§€ ì¶”ê°€
messages.append(HumanMessage(content="ì§ˆë¬¸"))

# 3. ì „ì²´ íˆìŠ¤í† ë¦¬ì™€ í•¨ê»˜ í˜¸ì¶œ
response = llm.invoke(messages)

# 4. ì‘ë‹µë„ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
messages.append(response)
```

### ì£¼ì˜ì‚¬í•­

- âš ï¸ í† í° ì œí•œ: ëŒ€í™”ê°€ ê¸¸ì–´ì§€ë©´ ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° ì´ˆê³¼
- âš ï¸ ë¹„ìš© ì¦ê°€: ë§¤ë²ˆ ì „ì²´ íˆìŠ¤í† ë¦¬ ì „ì†¡
- âš ï¸ ë©”ëª¨ë¦¬ ì „ëµ ì„ íƒ: ìƒí™©ì— ë§ëŠ” ì „ëµ í•„ìš”

---

## ì¶œì²˜

- [OpenAI - Chat Completions](https://platform.openai.com/docs/guides/chat-completions) - ê³µì‹ ë¬¸ì„œ
- [Anthropic - Claude Conversations](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering) - ê³µì‹ ë¬¸ì„œ
- [LangChain Memory Types](https://python.langchain.com/docs/modules/memory/types/) - ê³µì‹ ë¬¸ì„œ
- [LangGraph Persistence](https://langchain-ai.github.io/langgraph/how-tos/persistence/) - ìµœì‹  ê¶Œì¥ ë°©ì‹
- [Pinecone - LangChain Conversational Memory](https://www.pinecone.io/learn/series/langchain/langchain-conversational-memory/)
