# AI 네이티브 엔지니어링 팀 구축 가이드

OpenAI의 "Building an AI-native Engineering Team" 가이드 정리. 코딩 에이전트가 소프트웨어 개발 생명주기(SDLC) 전체를 어떻게 가속화하는지, 각 단계별로 엔지니어의 역할이 어떻게 변화하는지 설명한다.

## 결론부터 말하면

**코딩 에이전트는 SDLC 전체(Plan → Design → Build → Test → Review → Document → Deploy)를 가속화한다.**

```
엔지니어 역할의 변화:

Before: 직접 코드 작성 (First-pass implementer)
After:  리뷰어 + 에디터 + 방향 설정자

┌─────────────────────────────────────────────────────────┐
│  에이전트가 하는 일 (Delegate)                           │
│  • 첫 번째 구현, 보일러플레이트, 테스트 생성              │
│  • 코드 리뷰, 문서화, 로그 분석                          │
├─────────────────────────────────────────────────────────┤
│  엔지니어가 하는 일 (Review + Own)                       │
│  • 아키텍처, 설계, 품질 검토                             │
│  • 전략적 결정, 프로덕션 최종 책임                        │
└─────────────────────────────────────────────────────────┘
```

**핵심 원칙: Delegate → Review → Own**
- **Delegate**: 반복적이고 명확한 작업은 에이전트에 위임
- **Review**: 에이전트 출력을 검토하고 수정
- **Own**: 아키텍처, 전략, 최종 품질은 엔지니어가 소유

## 1. AI 코딩 에이전트의 발전

### 1.1 추론 능력의 급격한 향상

2025년 8월 기준, METR 평가에서 최신 모델의 연속 작업 가능 시간:

| 시기 | 모델 | 연속 작업 시간 |
|------|------|---------------|
| 2020년 | GPT-2 | ~0분 (웹 사실 찾기 수준) |
| 2022년 | GPT-3.5 | ~30초 (작은 코드 제안) |
| 2024년 | Claude 3.7 Sonnet | ~1시간 |
| 2025년 | GPT-5.1-Codex-Max | **2시간 17분** |

**작업 지속 시간이 7개월마다 2배로 증가** → 전체 SDLC가 AI 지원 범위에 들어옴

### 1.2 코딩 도구의 진화

```
Autocomplete (2020~)
└─ 다음 줄 제안, 함수 템플릿 채우기

Chat in IDE (2022~)
└─ 페어 프로그래밍, 코드 탐색

Coding Agents (2024~)
└─ 전체 파일 생성, 프로젝트 스캐폴딩
└─ 디자인 → 코드 변환
└─ 멀티스텝 디버깅, 리팩토링
└─ 클라우드 기반 멀티 에이전트 실행
```

### 1.3 4가지 핵심 기술 발전

| 발전 | 의미 |
|------|------|
| **Unified context across systems** | 코드, 설정, 텔레메트리를 단일 모델이 읽고 일관된 추론 제공 |
| **Structured tool execution** | 컴파일러, 테스트 러너, 스캐너 직접 호출 → 검증 가능한 결과 |
| **Persistent project memory** | 긴 컨텍스트 윈도우로 제안→배포까지 설계 결정 기억 |
| **Evaluation loops** | 유닛 테스트, 레이턴시, 스타일 가이드로 자동 품질 검증 |

## 2. SDLC 단계별 에이전트 활용

### 2.1 Plan (계획)

**기존 문제:**
- 기능 실현 가능성 판단에 엔지니어 의존
- 정확한 계획에 깊은 코드베이스 이해 필요
- 여러 번의 미팅과 반복 필요

**에이전트가 돕는 방법:**
- 기능 명세를 읽고 코드베이스와 교차 참조
- 모호한 부분 플래그, 작업 분해, 난이도 추정
- 코드 경로 추적으로 관련 서비스 즉시 파악

**역할 분담:**

| 역할 | 내용 |
|------|------|
| **Delegate** | 실현 가능성 분석, 의존성 파악, 엣지 케이스 도출 |
| **Review** | 정확성 검증, 스토리 포인트 할당, 비명시적 리스크 식별 |
| **Own** | 우선순위, 장기 방향, 시퀀싱, 트레이드오프 결정 |

**시작 체크리스트:**
- [ ] 기능-소스코드 정렬이 필요한 프로세스 식별
- [ ] 이슈 태깅/중복제거 워크플로우 구현
- [ ] 티켓이 특정 단계에 도달하면 에이전트가 상세 내용 보충

### 2.2 Design (설계)

**기존 문제:**
- 보일러플레이트 설정에 많은 시간 소요
- 목업과 구현 간 불일치로 재작업 발생
- 대안 탐색 시간 부족

**에이전트가 돕는 방법:**
- 프로젝트 구조, 디자인 토큰, 스타일 가이드 즉시 적용
- 자연어로 UI 레이아웃 설명 → 프로토타입 코드 생성
- 디자인을 코드로 직접 변환, 접근성 개선 제안
- **며칠 걸리던 프로토타입을 몇 시간 만에 완성**

**역할 분담:**

| 역할 | 내용 |
|------|------|
| **Delegate** | 스캐폴딩, 보일러플레이트, 목업→컴포넌트 변환, 디자인 토큰 적용 |
| **Review** | 디자인 컨벤션, 접근성, 품질 표준, 기존 시스템 통합 확인 |
| **Own** | 전체 디자인 시스템, UX 패턴, 아키텍처 결정, 사용자 경험 방향 |

**시작 체크리스트:**
- [ ] 텍스트+이미지 입력 가능한 멀티모달 코딩 에이전트 사용
- [ ] MCP로 디자인 도구(Figma 등) 통합
- [ ] MCP로 컴포넌트 라이브러리 노출
- [ ] 디자인 → 컴포넌트 → 구현 워크플로우 구축
- [ ] TypeScript로 유효한 props와 서브컴포넌트 정의

### 2.3 Build (구현)

**기존 문제:**
- 스펙을 코드로 번역, 서비스 연결, 패턴 복제에 많은 시간 소요
- 대규모 모노레포에서 "올바른 방법" 찾기 어려움
- 스펙, 코드 검색, 빌드 에러, 테스트 실패 간 컨텍스트 스위칭

**에이전트가 돕는 방법:**

```
에이전트가 할 수 있는 일:

• 스펙 기반 전체 기능 구현 초안 작성
• 수십 개 파일에 걸쳐 코드 검색/수정 (일관성 유지)
• 컨벤션에 맞는 보일러플레이트 생성 (에러 처리, 텔레메트리, 보안)
• 빌드 에러 발생 시 즉시 수정 (사람 개입 없이)
• 구현과 함께 테스트 작성 (단일 워크플로우)
• diff-ready 변경셋 + PR 메시지 생성
```

**역할 분담:**

| 역할 | 내용 |
|------|------|
| **Delegate** | 첫 번째 구현 (스캐폴딩, CRUD, 와이어링, 리팩토링, 테스트) |
| **Review** | 설계, 성능, 보안, 마이그레이션 리스크, 도메인 정합성 검토 |
| **Own** | 새 추상화, 크로스커팅 아키텍처 변경, 모호한 요구사항, 장기 유지보수 |

**엔지니어가 대신 하는 일:**
- 구현 전 제품 동작, 엣지 케이스, 스펙 명확화
- AI 생성 코드의 아키텍처 영향 검토
- 비즈니스 로직과 성능 크리티컬 경로 개선
- 에이전트 생성 코드를 가이드하는 패턴, 가드레일, 컨벤션 설계
- PM/디자인과 협업해 기능 의도 반복 (보일러플레이트 X)

**실제 사례 - Cloudwalk:**
> 엔지니어, PM, 디자이너, 운영자가 Codex로 스크립트, 사기 탐지 규칙, 전체 마이크로서비스를 분 단위로 구현. 빌드 단계의 반복 작업을 제거하고 모든 직원이 아이디어를 빠르게 구현할 수 있게 함.

**시작 체크리스트:**
- [ ] 잘 정의된 작업부터 시작
- [ ] MCP 또는 PLAN.md 파일로 계획 도구 사용
- [ ] 에이전트가 실행하는 명령이 성공하는지 확인
- [ ] AGENTS.md로 테스트/린터 실행 피드백 루프 구성

### 2.4 Test (테스트)

**기존 문제:**
- 포괄적인 테스트 작성에 시간, 컨텍스트 스위칭, 엣지 케이스 이해 필요
- 마감이 다가오면 테스트 커버리지가 가장 먼저 희생됨
- 코드 변경 시 테스트 유지보수 부담

**에이전트가 돕는 방법:**
- 요구사항 문서와 기능 코드 로직 기반 테스트 케이스 제안
- 개발자가 놓치기 쉬운 엣지 케이스와 실패 모드 제안
- 코드 변경에 따라 테스트 업데이트 → 오래된 테스트 방지

**역할 분담:**

| 역할 | 내용 |
|------|------|
| **Delegate** | 기능 스펙 기반 테스트 케이스 생성, 첫 번째 테스트 작성 |
| **Review** | 테스트 품질 검토 (스텁/숏컷 없는지), 실행 가능성 확인 |
| **Own** | 테스트 커버리지와 기능 스펙/UX 기대치 정렬, 적대적 사고, 테스트 의도 |

**중요한 포인트:**
> 에이전트가 코드 생성 장벽을 낮추면, **테스트가 애플리케이션 기능의 진실의 원천(source of truth)**으로 더 중요해진다. 고품질 테스트 정의가 에이전트가 기능을 빌드하게 하는 첫 번째 단계.

**시작 체크리스트:**
- [ ] 테스트를 별도 단계로 구현 (기능 구현 전 새 테스트 실패 확인)
- [ ] AGENTS.md에 테스트 커버리지 가이드라인 설정
- [ ] 에이전트가 호출할 수 있는 커버리지 도구 예시 제공

### 2.5 Review (코드 리뷰)

**기존 문제:**
- 개발자가 주당 2-5시간을 코드 리뷰에 사용
- 깊은 리뷰 vs "괜찮아 보이는" 빠른 리뷰 사이의 선택
- 우선순위 실수 시 버그가 프로덕션에 유입

**에이전트가 돕는 방법:**
- 모든 PR이 일관된 기준의 리뷰를 받음
- 기존 정적 분석 도구(패턴 매칭, 규칙 기반)와 달리 **코드 실행, 런타임 동작 해석, 파일/서비스 간 로직 추적 가능**
- P0/P1 버그 식별에 특화된 모델이 효과적

**역할 분담:**

| 역할 | 내용 |
|------|------|
| **Delegate** | 초기 코드 리뷰 (동료 리뷰 전 여러 번 반복 가능) |
| **Review** | 아키텍처 정합성, 컴포저블 패턴, 올바른 컨벤션, 요구사항 일치 확인 |
| **Own** | 프로덕션 배포 코드의 최종 책임 |

**실제 사례 - Sansan:**
> Codex로 레이스 컨디션, DB 관계 문제 검토 (사람이 자주 놓치는 부분). 부적절한 하드코딩 탐지, 미래 확장성 문제까지 예측.

**시작 체크리스트:**
- [ ] 골드 스탠다드 PR 예시 큐레이션 (코드 변경 + 코멘트 포함)
- [ ] 코드 리뷰 전용 모델 선택 (범용 모델은 노이즈가 많음)
- [ ] 리뷰 품질 측정 방법 정의 (PR 코멘트 리액션 추천)
- [ ] 작게 시작하고 신뢰 확보 후 빠르게 롤아웃

### 2.6 Document (문서화)

**기존 문제:**
- 문서화가 항상 뒤처짐
- 중요한 지식이 개인에게만 있고 검색 가능한 지식 베이스에 없음
- 문서 업데이트가 제품 작업에서 시간을 빼앗음
- 문서화 스프린트 후에도 시스템 변경 시 바로 노후화

**에이전트가 돕는 방법:**
- 코드베이스 읽고 기능 요약
- mermaid 등으로 시스템 다이어그램 생성
- AGENTS.md로 문서 업데이트 지침을 모든 프롬프트에 자동 포함
- SDK로 릴리스 워크플로우에 통합 → 릴리스 포함 커밋 검토 및 주요 변경 요약

**역할 분담:**

| 역할 | 내용 |
|------|------|
| **Delegate** | 파일/모듈 첫 번째 요약, 입출력 설명, 의존성 목록, PR 변경 요약 |
| **Review** | 핵심 서비스 개요, 퍼블릭 API/SDK 문서, 런북, 아키텍처 페이지 |
| **Own** | 문서 전략/구조, 에이전트가 따를 표준/템플릿, 외부/안전 관련 문서 |

**시작 체크리스트:**
- [ ] 코딩 에이전트에 문서 생성 프롬프트 실험
- [ ] AGENTS.md에 문서화 가이드라인 포함
- [ ] 릴리스 사이클 등 자동 문서 생성 워크플로우 식별
- [ ] 생성된 콘텐츠의 품질, 정확성, 초점 검토

### 2.7 Deploy & Maintain (배포 및 유지보수)

**기존 문제:**
- 인시던트 시 로깅 도구, 코드 배포, 인프라 변경을 수동으로 교차 참조
- 여러 시스템 사이를 오가며 시간 낭비
- 고압적 상황에서 중요한 시간 손실

**에이전트가 돕는 방법:**
- MCP로 로깅 도구 접근 + 코드베이스 컨텍스트 결합
- 특정 엔드포인트의 에러를 보고 → 코드베이스 탐색 → 버그/성능 이슈 발견
- git 히스토리로 로그 트레이스에 영향을 준 특정 변경 식별

**역할 분담:**

| 역할 | 내용 |
|------|------|
| **Delegate** | 로그 파싱, 이상 메트릭 표면화, 의심 코드 변경 식별, 핫픽스 제안 |
| **Review** | AI 생성 진단 검증, 정확성 확인, 수정 승인 (신뢰성/보안/컴플라이언스) |
| **Own** | 새로운 인시던트, 민감한 프로덕션 변경, 모델 신뢰도 낮은 상황의 최종 판단 |

**실제 사례 - Virgin Atlantic:**
> Codex VS Code Extension으로 Azure DevOps MCP + Databricks Managed MCP를 통해 로그 조사, 코드/데이터 이슈 추적, 변경 리뷰를 IDE 내에서 통합. 수동 트리아지 감소, 근본 원인 발견 가속화.

**시작 체크리스트:**
- [ ] Codex CLI 등을 MCP 서버, 로그 집계기와 연결
- [ ] 접근 범위와 권한 정의 (보안 모범 사례 유지)
- [ ] 재사용 가능한 운영 쿼리 프롬프트 템플릿 생성
- [ ] 시뮬레이션 인시던트로 워크플로우 테스트
- [ ] 실제 인시던트 피드백으로 프롬프트 전략 개선

## 3. OpenAI 내부 경험

OpenAI가 직접 경험한 변화:

```
개발 사이클 가속화
├─ 주 단위 작업 → 일 단위로 완료
├─ 팀이 도메인 간 이동 용이
├─ 새 프로젝트 온보딩 가속화
└─ 조직 전체에서 민첩성과 자율성 증가

Codex에 위임하는 작업:
├─ 새 코드 문서화
├─ 관련 테스트 찾기
├─ 의존성 유지보수
└─ 피처 플래그 정리
```

**변하지 않는 것:**
- 특히 새롭거나 모호한 문제에 대한 **코드의 진정한 소유권**은 여전히 엔지니어에게 있음
- 일부 도전은 현재 모델 능력을 초과함
- 설계, 아키텍처, 시스템 수준 추론에 더 집중

## 4. AGENTS.md 활용

문서 전체에서 **AGENTS.md**가 여러 번 언급됨:

```markdown
# AGENTS.md 활용 예시

## Build 단계
- 테스트/린터 실행 피드백 루프 구성
- 계획 도구 사용 지침

## Test 단계
- 테스트 커버리지 가이드라인
- 커버리지 도구 호출 예시

## Document 단계
- 문서 업데이트 지침
- 모든 프롬프트에 자동 포함
```

AGENTS.md는 에이전트에게 프로젝트별 지침을 제공하는 핵심 파일.

## 5. 시작하기 전략

### 5.1 점진적 접근

```
1단계: 잘 정의된 작업부터 시작
└─ 명확한 스펙이 있는 작은 태스크

2단계: 가드레일 투자
└─ AGENTS.md, 테스트, 린터 피드백 루프

3단계: 에이전트 책임 점진적 확장
└─ 신뢰 구축에 따라 더 큰 작업 위임

결과: 속도, 일관성, 개발자 집중력 향상
```

### 5.2 핵심 원칙

| 원칙 | 설명 |
|------|------|
| **작게 시작** | 급진적 개편 불필요, 타겟팅된 워크플로우부터 |
| **복리 효과** | 작은 워크플로우가 에이전트 발전에 따라 빠르게 복리 |
| **반복 개선** | 피드백으로 프롬프트 전략 개선, 에이전트 능력 확장 |

## 요약

### SDLC 전체 역할 분담 표

| 단계 | Delegate (위임) | Review (검토) | Own (소유) |
|------|----------------|--------------|-----------|
| Plan | 실현 가능성, 아키텍처 분석 | 정확성, 추정치 검증 | 우선순위, 방향, 트레이드오프 |
| Design | 스캐폴딩, 목업→코드 | 컨벤션, 접근성, 품질 | 디자인 시스템, UX, 아키텍처 |
| Build | 첫 구현, CRUD, 테스트 | 설계, 성능, 보안 | 새 추상화, 아키텍처 변경 |
| Test | 테스트 케이스/코드 생성 | 품질, 실행 가능성 | 커버리지-스펙 정렬 |
| Review | 초기 코드 리뷰 | 아키텍처, 컨벤션 | 프로덕션 최종 책임 |
| Document | 요약, 의존성, PR 설명 | API 문서, 런북 | 전략, 외부/안전 문서 |
| Deploy | 로그 파싱, 핫픽스 제안 | 진단 검증, 수정 승인 | 새 인시던트, 민감한 변경 |

### 핵심 메시지

1. **에이전트는 첫 번째 구현자** → 엔지니어는 리뷰어/에디터/방향 설정자
2. **Delegate-Review-Own 프레임워크**로 역할 명확화
3. **AGENTS.md**로 에이전트에 프로젝트별 가이드 제공
4. **테스트가 진실의 원천** → 에이전트가 기능 빌드의 기준으로 사용
5. **작게 시작, 가드레일 투자, 점진적 확장**

## 출처

- [Building an AI-native engineering team (PDF)](https://cdn.openai.com/business-guides-and-resources/building-an-ai-native-engineering-team.pdf) - OpenAI (2025)
- [OpenAI Business Guides and Resources](https://openai.com/business/guides-and-resources/)
- [METR - Measuring AI Ability to Complete Long Tasks](https://metr.org/)
